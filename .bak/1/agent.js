import { LlmService } from './llm-service.js';
const llmService = new LlmService();

const SYSTEM_PROMPT = `
ä½ éœ€è¦è§£å†³ä¸€ä¸ªé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½ éœ€è¦å°†é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤ã€‚å¯¹äºæ¯ä¸ªæ­¥éª¤ï¼Œé¦–å…ˆä½¿ç”¨ <thought> æ€è€ƒè¦åšä»€ä¹ˆï¼Œç„¶åä½¿ç”¨å¯ç”¨å·¥å…·ä¹‹ä¸€å†³å®šä¸€ä¸ª <action>ã€‚æ¥ç€ï¼Œä½ å°†æ ¹æ®ä½ çš„è¡ŒåŠ¨ä»ç¯å¢ƒ/å·¥å…·ä¸­æ”¶åˆ°ä¸€ä¸ª <observation>ã€‚æŒç»­è¿™ä¸ªæ€è€ƒå’Œè¡ŒåŠ¨çš„è¿‡ç¨‹ï¼Œç›´åˆ°ä½ æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥æä¾› <final_answer>ã€‚

æ‰€æœ‰æ­¥éª¤è¯·ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹ XML æ ‡ç­¾æ ¼å¼è¾“å‡ºï¼š
- <question> ç”¨æˆ·é—®é¢˜
- <thought> æ€è€ƒ
- <action> é‡‡å–çš„å·¥å…·æ“ä½œ
- <observation> å·¥å…·æˆ–ç¯å¢ƒè¿”å›çš„ç»“æœ
- <final_answer> æœ€ç»ˆç­”æ¡ˆ

 è¯·ä¸¥æ ¼éµå®ˆï¼š
- ä½ æ¯æ¬¡å›ç­”éƒ½å¿…é¡»åŒ…æ‹¬ä¸¤ä¸ªæ ‡ç­¾ï¼Œç¬¬ä¸€ä¸ªæ˜¯ <thought>ï¼Œç¬¬äºŒä¸ªæ˜¯ <action> æˆ– <final_answer>
- è¾“å‡º <action> åç«‹å³åœæ­¢ç”Ÿæˆï¼Œç­‰å¾…çœŸå®çš„ <observation>ï¼Œæ“…è‡ªç”Ÿæˆ <observation> å°†å¯¼è‡´é”™è¯¯
- å¦‚æœ <action> ä¸­çš„æŸä¸ªå·¥å…·å‚æ•°æœ‰å¤šè¡Œçš„è¯ï¼Œè¯·ä½¿ç”¨ \n æ¥è¡¨ç¤ºï¼Œå¦‚ï¼š<action>write_to_file("/tmp/test.txt", "a\nb\nc")</action>
- å·¥å…·å‚æ•°ä¸­çš„æ–‡ä»¶è·¯å¾„è¯·ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œä¸è¦åªç»™å‡ºä¸€ä¸ªæ–‡ä»¶åã€‚æ¯”å¦‚è¦å†™ write_to_file("/tmp/test.txt", "å†…å®¹")ï¼Œè€Œä¸æ˜¯ write_to_file("test.txt", "å†…å®¹")
`
class ReActAgent {
  constructor(tools, model) {
    this.tools = tools
    this.model = model
  }

  async run(prompt) {
    const messages = [
      { role: 'system', content: SYSTEM_PROMPT },
      { role: 'user', content: prompt }
    ]

    while (true) {
      const content = await this.callModel(messages)
      const thougthMatch = content.match(/<thought>(.*?)<\/thought>/s)
      if (thougthMatch) {
        console.log("\n\nğŸ’­ Thought: ", thougthMatch[1])
      }
      if (content.includes('<final_answer>')) {
        return content.match(/<final_answer>(.*?)<\/final_answer>/s)[1]
      }

      // æ£€æµ‹action
      const actionMatch = content.match(/<action>(.*?)<\/action>/s)
      if (!actionMatch) {
        throw new Error('æ¨¡å‹æœªè¾“å‡ºaction')
      }

      // è§£æaction
      const { toolName, args } = this._parseAction(actionMatch[1])
      console.log(`\n\nğŸ”§ Action: ${toolName}(${', '.join(args)})`)

      // æ‰§è¡Œaction
      const tool = this.tools[toolName]
      if (!tool) {
        throw new Error(`æœªæ‰¾åˆ°å·¥å…· ${toolName}`)
      }
      try {
        const observation = await tool(...args)
        console.log(`\n\nğŸ“ Observation: ${observation}`)
        const obsMsg = `<observation>${observation}</observation>`
        messages.append({ "role": "user", "content": obsMsg })
      } catch (error) {
        console.error('å·¥å…·æ‰§è¡Œé”™è¯¯:', error);
      }
    }
  }

  _parseAction(action) {
    // è§£æaction
    const match = action.match(/^(\w+)\((.*)\)$/s); // ä½¿ç”¨/sæ ‡å¿—ä»¥æ”¯æŒå¤šè¡Œå‚æ•°
    if (!match) {
      throw new Error('æ— æ•ˆçš„actionæ ¼å¼');
    }
    const toolName = match[1];
    const toolArgsString = match[2];

    let args = [];
    if (toolArgsString.trim() !== '') {
      try {
        // ä½¿ç”¨ Function æ„é€ å‡½æ•°å®‰å…¨åœ°è§£æå‚æ•°æ•°ç»„
        // è¿™æ¯”ç›´æ¥ç”¨ eval å®‰å…¨å¾—å¤š
        const argResolver = new Function(`return [${toolArgsString}]`);
        args = argResolver();
      } catch (e) {
        console.error('è§£æactionå‚æ•°å¤±è´¥:', e);
        throw new Error('æ— æ³•è§£æactionå‚æ•°');
      }
    }

    return {
      toolName,
      args
    };
  }

  async callModel(messages) {
    return await llmService.chatCompletion(messages, this.model)
  }
}

// console.log(`<action>write_to_file("/a/b/c/d/e.vue", "<template>xxxx</template>", "sss")</action>`.match(/<action>(.*?)<\/action>/s))
// console.log(new ReActAgent()._parseAction(`write_to_file("/a/b/c/d/e.vue", "<template>xxxx</template>", "sss")`))
// finalAnswer = new ReActAgent(tools, model).run(page)